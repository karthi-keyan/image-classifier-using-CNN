{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#importing required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "ses=tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#preprocessing data (image into numpy array)\n",
    "#splitting it for training and testing\n",
    "#here train labels are one hot encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.chdir(\"C:/Users/karthi/Desktop/image_classifier\")\n",
    "train_images=os.listdir(\"train_images/\")\n",
    "test_images=os.listdir(\"test_images/\")\n",
    "train_images_data=[]\n",
    "test_images_data=[]\n",
    "train_images_label=[]\n",
    "for img in train_images:\n",
    "    data=Image.open(\"train_images/{}\".format(img))\n",
    "    data=np.array(data.getdata()).reshape([1,128,128,3]).astype(\"float32\")\n",
    "    train_images_data.append(data)\n",
    "for img in test_images:\n",
    "    data=Image.open(\"test_images/{}\".format(img))\n",
    "    data=np.array(data.getdata()).reshape([1,128,128,3]).astype(\"float32\")\n",
    "    test_images_data.append(data)\n",
    "for i in range(0,283):\n",
    "    if i<139:\n",
    "        train_images_label.append(np.array([1,0]).astype('float32'))\n",
    "    else:\n",
    "        train_images_label.append(np.array([0,1]).astype('float32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#creating required weights and biases\n",
    "#here number of epochs 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x=tf.placeholder(\"float32\",[1,128,128,3])\n",
    "y=tf.placeholder('float32',[1,2])\n",
    "conv_layer1={\"weights\":tf.Variable(tf.truncated_normal([3,3,3,3])),\"bias\":tf.Variable(tf.random_normal([3]))}\n",
    "conv_layer2={\"weights\":tf.Variable(tf.truncated_normal([5,5,3,32])),\"bias\":tf.Variable(tf.random_normal([32]))}\n",
    "conv_layer3={\"weights\":tf.Variable(tf.truncated_normal([6,6,32,64])),\"bias\":tf.Variable(tf.random_normal([64]))}\n",
    "fc_layer1={\"weights\":tf.Variable(tf.truncated_normal([32*32*64,600])),\"bias\":tf.Variable(tf.random_normal([600]))}\n",
    "out_layer={\"weights\":tf.Variable(tf.truncated_normal([600,2])),\"bias\":tf.Variable(tf.random_normal([2]))}\n",
    "no_epoch=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#defining the convolution layer and fully connected layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv_classify(x):\n",
    "    print(\"==========================================================\")\n",
    "    con1=tf.nn.conv2d(x,conv_layer1[\"weights\"],strides=[1,1,1,1],padding=\"SAME\")+conv_layer1[\"bias\"]\n",
    "    print(\"convolution layer1 {}   filter  3X3\".format(con1.shape))\n",
    "    con1=tf.nn.relu(con1)\n",
    "    print(\"relu {}\".format(con1.shape))\n",
    "    print(\"==========================================================\")\n",
    "    con2=tf.nn.conv2d(con1,conv_layer2[\"weights\"],strides=[1,1,1,1],padding=\"SAME\")+conv_layer2[\"bias\"]\n",
    "    print(\"convolution layer2 {}   filter  5X5\".format(con2.shape))\n",
    "    con2=tf.nn.relu(con2)\n",
    "    print(\"relu {}\".format(con2.shape))\n",
    "    con2=tf.nn.max_pool(con2,ksize=[1,2,2,1],strides=[1,2,2,1],padding=\"SAME\")\n",
    "    print(\"maxpool layer {}   filter  2X2\".format(con2.shape))\n",
    "    print(\"==========================================================\")\n",
    "    con3=tf.nn.conv2d(con2,conv_layer3[\"weights\"],strides=[1,1,1,1],padding=\"SAME\")+conv_layer3[\"bias\"]\n",
    "    print(\"convolution layer3 {}   filter  6X6\".format(con3.shape))\n",
    "    con3=tf.nn.relu(con3)\n",
    "    print(\"relu {}\".format(con3.shape))\n",
    "    con3=tf.nn.max_pool(con3,ksize=[1,2,2,1],strides=[1,2,2,1],padding=\"SAME\")\n",
    "    print(\"maxpool layer {}   filter  2X2\".format(con3.shape))\n",
    "    print(\"==========================================================\")\n",
    "    con3=tf.reshape(con3,[-1,32*32*64])\n",
    "    fc=tf.add(tf.matmul(con3,fc_layer1[\"weights\"]),fc_layer1[\"bias\"])\n",
    "    fc=tf.nn.sigmoid(fc)\n",
    "    print(\"fully connected layer {}\".format(fc.shape))\n",
    "    fc=tf.nn.dropout(fc,0.75)\n",
    "    out=tf.add(tf.matmul(fc,out_layer[\"weights\"]),out_layer[\"bias\"])\n",
    "    out=tf.nn.sigmoid(out)\n",
    "    print(\"output layer {}\".format(out.shape))\n",
    "    print(\"==========================================================\")\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#training the  network \n",
    "#here it trains to find whether given image is cat or car"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================\n",
      "convolution layer1 (1, 128, 128, 3)   filter  3X3\n",
      "relu (1, 128, 128, 3)\n",
      "==========================================================\n",
      "convolution layer2 (1, 128, 128, 32)   filter  5X5\n",
      "relu (1, 128, 128, 32)\n",
      "maxpool layer (1, 64, 64, 32)   filter  2X2\n",
      "==========================================================\n",
      "convolution layer3 (1, 64, 64, 64)   filter  6X6\n",
      "relu (1, 64, 64, 64)\n",
      "maxpool layer (1, 32, 32, 64)   filter  2X2\n",
      "==========================================================\n",
      "fully connected layer (1, 600)\n",
      "output layer (1, 2)\n",
      "==========================================================\n",
      "Training network\n",
      "epoch 1 of 20 total loss: 139.8433881591624\n",
      "epoch 2 of 20 total loss: 114.54857212211084\n",
      "epoch 3 of 20 total loss: 109.76856463274288\n",
      "epoch 4 of 20 total loss: 96.76864407090589\n",
      "epoch 5 of 20 total loss: 72.9628610807757\n",
      "epoch 6 of 20 total loss: 79.60532039504521\n",
      "epoch 7 of 20 total loss: 49.66609136263518\n",
      "epoch 8 of 20 total loss: 52.15510767518204\n",
      "epoch 9 of 20 total loss: 39.490946154916934\n",
      "epoch 10 of 20 total loss: 37.03677648686858\n",
      "epoch 11 of 20 total loss: 30.89101963000808\n",
      "epoch 12 of 20 total loss: 34.63225539487312\n",
      "epoch 13 of 20 total loss: 23.594365963083206\n",
      "epoch 14 of 20 total loss: 26.93971385915988\n",
      "epoch 15 of 20 total loss: 25.867966730921296\n",
      "epoch 16 of 20 total loss: 22.31002000843364\n",
      "epoch 17 of 20 total loss: 15.027351865766057\n",
      "epoch 18 of 20 total loss: 19.174114838271343\n",
      "epoch 19 of 20 total loss: 16.554401463405032\n",
      "epoch 20 of 20 total loss: 15.418552468271338\n",
      "training completed\n"
     ]
    }
   ],
   "source": [
    "pred=conv_classify(x)\n",
    "print(\"Training network\")\n",
    "cost=tf.reduce_mean(tf.square(pred-y))\n",
    "optimiser=tf.train.AdamOptimizer().minimize(cost)\n",
    "ses.run(tf.global_variables_initializer())\n",
    "for epoch in range(0,no_epoch):\n",
    "    epoch_loss=0\n",
    "    for pic in range(0,283):\n",
    "        _,cost_,y_,predi=ses.run([optimiser,cost,y,pred],feed_dict={x:train_images_data[pic],y:train_images_label[pic].reshape([1,2])})\n",
    "        epoch_loss=epoch_loss+cost_\n",
    "    print(\"epoch {} of {} total loss: {}\".format(epoch+1,no_epoch,epoch_loss))\n",
    "print(\"training completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#testing the images whether it predicting correctly or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test images\n",
      "[[  6.42847226e-06   1.00000000e+00]]\n",
      "1.png is car\n",
      "[[  9.99999642e-01   1.84064266e-08]]\n",
      "2.png is cat\n",
      "[[  1.00000000e+00   7.16541919e-08]]\n",
      "gvhvkvkj.png is cat\n",
      "[[  1.00000000e+00   1.55696025e-08]]\n",
      "obj14__175.png is cat\n",
      "[[  9.99999285e-01   3.05524921e-08]]\n",
      "obj14__245.png is cat\n",
      "[[ 1.          0.00963312]]\n",
      "obj14__70.png is cat\n",
      "[[  2.68070662e-22   1.00000000e+00]]\n",
      "obj6__230.png is car\n",
      "[[  2.09741495e-11   1.00000000e+00]]\n",
      "obj6__260.png is car\n",
      "[[  4.58630436e-16   1.00000000e+00]]\n",
      "obj6__355.png is car\n",
      "[[  1.36555467e-13   1.00000000e+00]]\n",
      "z.png is car\n"
     ]
    }
   ],
   "source": [
    "print(\"test images\")\n",
    "for i in range(0,10):\n",
    "    ggg=ses.run(pred,feed_dict={x:test_images_data[i]})\n",
    "    print(ggg)\n",
    "    maxi=max(ggg[0])\n",
    "    if ggg[0][0]==maxi:\n",
    "        print(\"{} is cat\".format(test_images[i])) \n",
    "    else:\n",
    "        print(\"{} is car\".format(test_images[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
